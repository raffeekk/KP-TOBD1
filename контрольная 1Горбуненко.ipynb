{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c07f18",
   "metadata": {},
   "source": [
    "# Контрольная работа №1\n",
    "\n",
    "Каждая задача решается в отдельном ноутбуке, код содержит комментарии, объясняющие вычисления.\n",
    "\n",
    "Этот ноутбук подготовлен для запуска в Google Colab. Если вы откроете его в Colab — выполните клетки по порядку. Если какие-то файлы отсутствуют (diabetes_dataset.csv, image1.jpg), Colab предложит загрузить их вручную.\n",
    "\n",
    "---\n",
    "\n",
    "**Содержание ноутбука**:\n",
    "1. Fourier-преобразование для `jena_climate_2009_2016.csv` (скачивание при необходимости), построение спектра плотности и восстановленного ряда.\n",
    "2. PCA для `diabetes_dataset.csv`: предобработка, PCA, диаграмма первых 2 компонент с раскраской по `diagnosed_diabetes`.\n",
    "3. Сжатие `image1.jpg` методом FFT и методом SVD: график сингулярных значений, спектра мощности, измерение среднего времени выполнения и объёма сжатых данных.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76509220",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Часть 1 — Fourier-преобразование для jena_climate_2009_2016.csv\n",
    "# Код автоматически скачивает dataset TensorFlow (если запущен в Colab) или пытается открыть локальный файл.\n",
    "# Мы будем работать с температурой 'T (degC)'.\n",
    "\n",
    "import os\n",
    "import io\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, ifft, fftfreq\n",
    "from scipy.signal import welch\n",
    "\n",
    "# Если запускаете в Colab — можно скачать архив с датасетом TensorFlow. Если нет — загрузите файл вручную.\n",
    "jena_fname = 'jena_climate_2009_2016.csv'\n",
    "if not os.path.exists(jena_fname):\n",
    "    try:\n",
    "        print('Файл не найден локально — пытаюсь скачать архив TensorFlow...')\n",
    "        !wget -q https://storage.googleapis.com/tensorflow/tf-keras-datasets/jena_climate_2009_2016.csv.zip -O jena.zip\n",
    "        !unzip -o jena.zip -d .\n",
    "        if not os.path.exists(jena_fname):\n",
    "            raise Exception('Не удалось скачать файл автоматически. Загрузите jena_climate_2009_2016.csv вручную.')\n",
    "        else:\n",
    "            print('Файл скачан и распакован.')\n",
    "    except Exception as e:\n",
    "        print('Автоматическое скачивание не удалось:', e)\n",
    "        from google.colab import files\n",
    "        print('Пожалуйста, загрузите jena_climate_2009_2016.csv вручную.')\n",
    "        uploaded = files.upload()  # запустится в Colab\n",
    "        for k in uploaded.keys():\n",
    "            print('Загружен', k)\n",
    "\n",
    "# Загружаем csv\n",
    "df = pd.read_csv(jena_fname)\n",
    "# Показываем колонки — чтобы найти нужную колонку температуры\n",
    "print('Колонки датасета:', df.columns.tolist())\n",
    "\n",
    "# Обычно в этом датасете колонка с температурой называется 'T (degC)'\n",
    "temp_col = None\n",
    "candidates = ['T (degC)', 'T', 'Air temperature (degC)']\n",
    "for c in candidates:\n",
    "    if c in df.columns:\n",
    "        temp_col = c\n",
    "        break\n",
    "if temp_col is None:\n",
    "    # если структура другая — возьмём первую числовую колонку\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    temp_col = numeric_cols[0]\n",
    "    print('Не найдена стандартная колонка температуры, используем', temp_col)\n",
    "else:\n",
    "    print('Используем температурную колонку:', temp_col)\n",
    "\n",
    "signal = df[temp_col].astype(float).values\n",
    "times = pd.to_datetime(df['Date Time']) if 'Date Time' in df.columns else None\n",
    "\n",
    "# Для анализа возьмём более короткий фрагмент (примерно 10 000 точек) чтобы быстрее выполнять демонстрацию\n",
    "n = min(len(signal), 20000)\n",
    "signal = signal[:n]\n",
    "if times is not None:\n",
    "    times = times[:n]\n",
    "\n",
    "# Убираем среднее — для спектрального анализа\n",
    "signal_mean = signal.mean()\n",
    "signal_centered = signal - signal_mean\n",
    "\n",
    "# Быстрое преобразование Фурье\n",
    "N = len(signal_centered)\n",
    "yf = fft(signal_centered)\n",
    "xf = fftfreq(N, d=1.0)  # в данном датасете шаг времени — 10 минут, но используем d=1 условно\n",
    "power = np.abs(yf)**2 / N\n",
    "\n",
    "# Оценка спектра мощности с помощью Welch для сравнения\n",
    "f_welch, Pxx = welch(signal_centered, nperseg=1024)\n",
    "\n",
    "# Строим график спектра плотности мощности и временного ряда до/после фильтрации\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(f_welch[:len(f_welch)//10], Pxx[:len(Pxx)//10])\n",
    "plt.title('PSD (Welch) — низкочастотная часть')\n",
    "plt.xlabel('Частота (условн.)')\n",
    "plt.ylabel('Мощность')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.semilogy(np.fft.fftshift(fftfreq(N)), np.fft.fftshift(power))\n",
    "plt.title('Полный спектр мощности (лог шкала)')\n",
    "plt.xlabel('Частота (условн.)')\n",
    "plt.ylabel('Мощность (лог)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Фильтрация: оставим только низкие частоты — например, уберём компоненты с индексами, чей модуль больше cutoff\n",
    "# Подход: выбрать порог по доле полной мощности (например, сохранить 90% мощности в низкочастотной области),\n",
    "# или выбрать фиксированный cutoff (например, топ k низкочастотных компонент).\n",
    "# Здесь реализуем простой метод: сохраняем компоненты с |freq_index| < k_low\n",
    "k_low = int(0.01 * N)  # оставляем 1% нижних частот по индексам\n",
    "mask = np.zeros(N, dtype=bool)\n",
    "mask[:k_low] = True\n",
    "mask[-k_low:] = True  # симметрично\n",
    "yf_filtered = yf * mask\n",
    "reconstructed = np.real(ifft(yf_filtered)) + signal_mean\n",
    "\n",
    "# Построим оригинал и реконструкцию\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(signal, label='Оригинал (фрагмент)')\n",
    "plt.plot(reconstructed, label=f'Реконструкция (низкие частоты, k_low={k_low})', linewidth=2)\n",
    "plt.legend()\n",
    "plt.title('Временной ряд: до и после фильтрации FFT')\n",
    "plt.xlabel('Индекс времени')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Покажем долю мощности, сохранённой после фильтрации\n",
    "power_total = power.sum()\n",
    "power_filtered = (np.abs(yf_filtered)**2 / N).sum()\n",
    "print(f'Доля мощности, сохранённой низкими частотами: {power_filtered/power_total:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d674c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Часть 2 — PCA для diabetes_dataset.csv\n",
    "# Ожидается, что файл diabetes_dataset.csv загружен в рабочую папку. Если нет — Colab предложит загрузить.\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fname = 'diabetes_dataset.csv'\n",
    "if not os.path.exists(fname):\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print('Файл diabetes_dataset.csv не найден. Загрузите его сейчас.')\n",
    "        uploaded = files.upload()\n",
    "        for k in uploaded.keys():\n",
    "            print('Загружен', k)\n",
    "    except Exception as e:\n",
    "        print('Запуск вне Colab — убедитесь, что diabetes_dataset.csv находится в текущей папке.')\n",
    "\n",
    "df = pd.read_csv(fname)\n",
    "print('Первые строки датасета:')\n",
    "display(df.head())\n",
    "\n",
    "# Найдём целевой столбец 'diagnosed_diabetes' (возможны варианты регистра)\n",
    "target_cols = [c for c in df.columns if c.lower()=='diagnosed_diabetes' or c.lower().endswith('diagnosed_diabetes')]\n",
    "if not target_cols:\n",
    "    # Попробуем варианты: 'diabetes', 'Outcome', 'target'\n",
    "    for alt in ['diabetes','Outcome','target','Diagnosis','diagnosed']:\n",
    "        if alt in df.columns:\n",
    "            target_cols = [alt]; break\n",
    "if not target_cols:\n",
    "    raise ValueError('Не найден столбец с метками диабета. Пожалуйста, проверьте название столбца (ожидается diagnosed_diabetes).')\n",
    "\n",
    "target_col = target_cols[0]\n",
    "print('Используем столбец меток:', target_col)\n",
    "\n",
    "# Предобработка: преобразуем категориальные признаки в числа (LabelEncoder) или удалим сильно текстовые столбцы\n",
    "X = df.drop(columns=[target_col]).copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "# Простейшая обработка: для нечисловых столбцов применим LabelEncoder (потенциально лучше — one-hot, но для PCA допускается кодировка целыми числами)\n",
    "for c in X.columns:\n",
    "    if X[c].dtype == 'object' or X[c].dtype.name == 'category':\n",
    "        le = LabelEncoder()\n",
    "        X[c] = le.fit_transform(X[c].astype(str))\n",
    "\n",
    "# Удалим колонки с Nan или заменим средним\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Масштабирование перед PCA\n",
    "scaler = StandardScaler()\n",
    "Xs = scaler.fit_transform(X)\n",
    "\n",
    "# Применяем PCA и выводим первые 2 компоненты\n",
    "pca = PCA(n_components=2)\n",
    "pcs = pca.fit_transform(Xs)\n",
    "\n",
    "print('Доля объяснённой дисперсии по компонентам:', pca.explained_variance_ratio_)\n",
    "\n",
    "# Визуализация: первые 2 компоненты\n",
    "plt.figure(figsize=(8,6))\n",
    "# Преобразуем метки в 0/1 если необходимо\n",
    "try:\n",
    "    y_num = pd.to_numeric(y, errors='coerce')\n",
    "    mask_nan = np.isnan(y_num)\n",
    "    if mask_nan.any():\n",
    "        # если не получилось — применим LabelEncoder\n",
    "        from sklearn.preprocessing import LabelEncoder\n",
    "        y_num = LabelEncoder().fit_transform(y.astype(str))\n",
    "except Exception:\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    y_num = LabelEncoder().fit_transform(y.astype(str))\n",
    "\n",
    "plt.scatter(pcs[:,0], pcs[:,1], c=y_num, cmap='viridis', s=20, alpha=0.7)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('PCA: первые 2 главные компоненты (цвет = diagnosed_diabetes)')\n",
    "plt.colorbar(label='diagnosed_diabetes (код)')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688562b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Часть 3 — Сжатие изображения image1.jpg: FFT и SVD\n",
    "# Ожидается файл image1.jpg в рабочей папке; если нет — Colab предложит загрузить.\n",
    "import os, time\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.fft import fft2, ifft2, fftshift, ifftshift\n",
    "from scipy.linalg import svd\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "img_fname = 'image1.jpg'\n",
    "if not os.path.exists(img_fname):\n",
    "    try:\n",
    "        from google.colab import files\n",
    "        print('Файл image1.jpg не найден. Загрузите его сейчас.')\n",
    "        uploaded = files.upload()\n",
    "        for k in uploaded.keys():\n",
    "            print('Загружен', k)\n",
    "    except Exception as e:\n",
    "        print('Запуск вне Colab — убедитесь, что image1.jpg находится в текущей папке.')\n",
    "\n",
    "img = Image.open(img_fname).convert('RGB')\n",
    "arr = np.array(img).astype(float)/255.0  # нормируем для обработки\n",
    "h,w,c = arr.shape\n",
    "print(f'Изображение: {img_fname}, размер {w}x{h}, каналы: {c}')\n",
    "\n",
    "# Функция FFT-сжатия: обнуляем малую часть спектра (по доле мощности)\n",
    "def fft_compress(channel, keep_fraction=0.1):\n",
    "    # channel: 2D array\n",
    "    F = fft2(channel)\n",
    "    magnitude = np.abs(F)\n",
    "    # оставим только верхние по модулю коэффициенты\n",
    "    flat = magnitude.flatten()\n",
    "    threshold = np.sort(flat)[-int(len(flat)*keep_fraction)] if keep_fraction>0 else np.inf\n",
    "    mask = magnitude >= threshold\n",
    "    F_comp = F * mask\n",
    "    rec = np.real(ifft2(F_comp))\n",
    "    return rec, mask\n",
    "\n",
    "# Функция SVD-сжатия на каждом канале: оставляем k сингулярных значений\n",
    "def svd_compress(channel, k):\n",
    "    U, s, Vt = svd(channel, full_matrices=False)\n",
    "    S = np.zeros((k,k))\n",
    "    S[:k,:k] = np.diag(s[:k])\n",
    "    rec = (U[:,:k] @ np.diag(s[:k]) @ Vt[:k,:])\n",
    "    return rec, s\n",
    "\n",
    "# Эксперимент: измерим среднее время и объём сжатых данных для нескольких параметров\n",
    "fft_results = {}\n",
    "svd_results = {}\n",
    "\n",
    "ks = [5, 20, 50]  # для SVD\n",
    "keep_fracs = [0.01, 0.05, 0.1]  # для FFT\n",
    "\n",
    "# повторов для усреднения\n",
    "repeats = 3\n",
    "\n",
    "for keep in keep_fracs:\n",
    "    t0 = timer()\n",
    "    masks = []\n",
    "    rec_channels = []\n",
    "    for ch in range(3):\n",
    "        total_t = 0.0\n",
    "        for r in range(repeats):\n",
    "            start = timer()\n",
    "            rec, mask = fft_compress(arr[:,:,ch], keep_fraction=keep)\n",
    "            total_t += (timer() - start)\n",
    "        rec_channels.append(rec)\n",
    "        masks.append(mask)\n",
    "    t_avg = total_t / repeats\n",
    "    rec_img = np.clip(np.stack(rec_channels,axis=2),0,1)\n",
    "    # вычислим объём сжатых данных: количество ненулевых коэффициентов в F для всех каналов\n",
    "    nonzeros = sum([m.sum() for m in masks])\n",
    "    # Оценим \"объём\" в байтах: число комплексных коэффициентов * 16 байт (double для реальной и мнимой части)\n",
    "    est_bytes = nonzeros * 16\n",
    "    fft_results[keep] = {'time_avg': t_avg, 'nonzeros': int(nonzeros), 'est_bytes': int(est_bytes), 'reconstruction': rec_img}\n",
    "\n",
    "for k in ks:\n",
    "    total_t = 0.0\n",
    "    rec_channels = []\n",
    "    nonzeros = 0\n",
    "    singular_values_all = []\n",
    "    for ch in range(3):\n",
    "        # усредняем по повтору выполнения SVD (SVD сам по себе детерминированный)\n",
    "        start = timer()\n",
    "        rec, s = svd_compress(arr[:,:,ch], k)\n",
    "        total_t += (timer() - start)\n",
    "        rec_channels.append(rec)\n",
    "        singular_values_all.append(s)\n",
    "        nonzeros += (arr.shape[0]*k + k + k*arr.shape[1])  # числа параметров U (n*k) + diag(k) + Vt (k*m)\n",
    "    t_avg = total_t  # для SVD не делаем многократных повтора (дорого), оставляем время 1 прохода\n",
    "    rec_img = np.clip(np.stack(rec_channels,axis=2),0,1)\n",
    "    est_bytes = nonzeros * 8  # приблизительно, double 8 байт на число\n",
    "    svd_results[k] = {'time': t_avg, 'params': int(nonzeros), 'est_bytes': int(est_bytes), 'reconstruction': rec_img, 'singular_values': singular_values_all}\n",
    "\n",
    "# Показ результатов: оригинал, FFT-реконструкция (пример), SVD-реконструкция (пример)\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.subplot(2,3,1); plt.imshow(arr); plt.title('Оригинал'); plt.axis('off')\n",
    "# выберем keep=0.05 для демонстрации\n",
    "k_example = ks[1]\n",
    "keep_example = keep_fracs[1]\n",
    "plt.subplot(2,3,2); plt.imshow(fft_results[keep_example]['reconstruction']); plt.title(f'FFT rec keep={keep_example}'); plt.axis('off')\n",
    "plt.subplot(2,3,3); plt.imshow(svd_results[k_example]['reconstruction']); plt.title(f'SVD rec k={k_example}'); plt.axis('off')\n",
    "\n",
    "# график сингулярных значений (для первого канала)\n",
    "svals = svd_results[k_example]['singular_values'][0]\n",
    "plt.subplot(2,3,4); plt.plot(svals, marker='o'); plt.title('Сингулярные значения (канал 0)'); plt.xlabel('i'); plt.ylabel('s_i')\n",
    "plt.subplot(2,3,5); plt.semilogy(svals, marker='o'); plt.title('Сингулярные значения (лог шкала)'); plt.xlabel('i')\n",
    "plt.subplot(2,3,6)\n",
    "# спектр мощности канала 0\n",
    "F = fft2(arr[:,:,0])\n",
    "power = np.abs(F)**2\n",
    "plt.imshow(fftshift(np.log1p(power)), aspect='auto')\n",
    "plt.title('Спектр мощности (лог) канала 0'); plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Выведем таблицу с результатами оценки времени и объёма\n",
    "import pandas as pd\n",
    "rows = []\n",
    "for keep,v in fft_results.items():\n",
    "    rows.append({'method':'FFT','param':f'keep={keep}','time_avg_s':v['time_avg'],'nonzeros':v['nonzeros'],'est_bytes':v['est_bytes']})\n",
    "for k,v in svd_results.items():\n",
    "    rows.append({'method':'SVD','param':f'k={k}','time_avg_s':v['time'],'nonzeros':v['params'],'est_bytes':v['est_bytes']})\n",
    "df_res = pd.DataFrame(rows).sort_values(['method','param'])\n",
    "display(df_res)\n",
    "\n",
    "# Сохраним примеры реконструкций\n",
    "from PIL import Image\n",
    "def save_img(arr_norm, fname):\n",
    "    im = Image.fromarray((np.clip(arr_norm,0,1)*255).astype('uint8'))\n",
    "    im.save(fname)\n",
    "\n",
    "save_img(fft_results[keep_example]['reconstruction'], 'fft_reconstruction_example.jpg')\n",
    "save_img(svd_results[k_example]['reconstruction'], 'svd_reconstruction_example.jpg')\n",
    "print('Сохранены примеры: fft_reconstruction_example.jpg, svd_reconstruction_example.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e10a9f9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Как использовать ноутбук**:\n",
    "\n",
    "1. Откройте `Control_Work1_Colab.ipynb` в Google Colab.\n",
    "2. Запустите клетки сверху вниз. Если Colab запросит загрузить `diabetes_dataset.csv` или `image1.jpg`, загрузите их.\n",
    "3. Просмотрите графики и сохранённые примеры реконструкций (`fft_reconstruction_example.jpg`, `svd_reconstruction_example.jpg`).\n",
    "\n",
    "Если хотите, могу сейчас сохранить этот ноутбук и дать ссылку для скачивания. Обычно файл появится по пути `/mnt/data/Control_Work1_Colab.ipynb`.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
